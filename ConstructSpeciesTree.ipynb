{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/databases/OMA/OMA.2.1.1/data/OmaServer.h5']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('/data/databases/OMA/OMA.2.1.1/data/*')\n",
    "print files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add pyoma functions\n",
    "import sys\n",
    "sys.path.append('/home/USERNAME/pyoma')\n",
    "import pyoma as po\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "omadata = '/data/databases/OMA/OMA.2.1.1/data/OmaServer.h5'\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import ete3 as ete3\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#create a distmat for all species in the NCBI taxonomy\n",
    "table = tb.open_file(omadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Build a Taxonomic Tree</h1>\n",
    "The next cell takes the Taxonomy data in OMA and builds an ete3 tree object from it. We can use this object to select reference taxa for use in our co-evolution analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building taxonomic tree\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Add LUCA to start off the tree\n",
    "t = ete3.Tree()\n",
    "t.add_feature( 'SciName' , 'LUCA')\n",
    "t.add_feature( 'ParentTaxonID' , 'None')\n",
    "t.name = '0'\n",
    "\n",
    "IdtoName={}\n",
    "nameToID={}\n",
    "\n",
    "IdtoName[0] = 'LUCA'\n",
    "nameToID['LUCA']= str(0)\n",
    "    \n",
    "\n",
    "\n",
    "#cout of all nodes in the tree\n",
    "nodes =1\n",
    "    \n",
    "print 'Building taxonomic tree'\n",
    "for i,line in enumerate(table.root.Taxonomy):\n",
    "    if i %1000 ==0:\n",
    "        print i\n",
    "    IdtoName[str(line[0])] = str(line[2])\n",
    "    nameToID[str(line[2])]= str(line[0])\n",
    "    \n",
    "    child = t.search_nodes(name=str(line[1]))[0].add_child(name=str(line[0]) )\n",
    "    child.add_feature( 'SciName' ,  line[2])\n",
    "    child.add_feature( 'ParentTaxonID' , line[1])\n",
    "    nodes +=1\n",
    "print 'DONE'\n",
    "\n",
    "handle1= open('./IdtoName.pkl','w')\n",
    "handle2= open('./NameToID.pkl','w')\n",
    "\n",
    "pickle.dump(IdtoName, handle1, -1)\n",
    "pickle.dump(nameToID, handle2, -1)\n",
    "handle1.close()\n",
    "handle2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2071\n",
      "species\n",
      "4167\n",
      "taxonomic IDs\n"
     ]
    }
   ],
   "source": [
    "#define a little wrapping function to allow the multiprocess library map function \n",
    "# to use the distance function from ete3\n",
    "\n",
    "def get_dist(args):\n",
    "    n,m = args\n",
    "    return n.get_distance(m, topology_only = True)\n",
    "\n",
    "#this is the distance matrix between all taxa\n",
    "distmat = np.zeros((nodes, nodes ) ) \n",
    "column_dict = {}\n",
    "print len(t)\n",
    "print 'species'\n",
    "print nodes\n",
    "print 'taxonomic IDs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> calculate the lower triangular distance matrix between all species in the tree </h1>\n",
    "go through each node in the taxonomic tree and compute it's distance to all other nodes. Since m to n is the same distance as n to m we should only calculate the lower triangular matrix and add it to it's transvers to construct the final distance matrix. These distance only reflect topological distance in the species tree and not an actual evolutionary/time distance but it's still useful for grouping species/ selecting taxa etc...\n",
    "\n",
    "This is a pretty heavy calculation to run. Would just recommend loading the pickled matrix to play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing lower triangular distmat\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "maxjobs = 100000\n",
    "jobs = []\n",
    "coords=[]\n",
    "print 'Computing lower triangular distmat'\n",
    "for i,n in enumerate(t.traverse()):\n",
    "    column_dict[n.name] = i\n",
    "    for j, m in enumerate(t.traverse()):\n",
    "        if i < j :\n",
    "            coords.append([i,j])\n",
    "            jobs.append([n,m])      \n",
    "            if len(jobs)> maxjobs:\n",
    "                pool = Pool()\n",
    "                results = pool.map_async(get_dist,jobs).get()\n",
    "                for k, coord in enumerate(coords):\n",
    "                    i,j = coord\n",
    "                    distmat[i,j] = results[k]\n",
    "                jobs =[]\n",
    "                coords =[]\n",
    "                pool.close()\n",
    "#run the leftovers     \n",
    "pool = Pool()\n",
    "results = pool.map_async(get_dist,jobs).get()\n",
    "pool.close()\n",
    "for k, coord in enumerate(coords):\n",
    "    i,j = coord\n",
    "    distmat[i,j] = results[k]       \n",
    "distmat = distmat + distmat.T\n",
    "print 'DONE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "handle1 = open( './distmat.pkl','w')\n",
    "handle2 = open( './column_dict.pkl' , 'w')\n",
    "pickle.dump(distmat,handle1, -1)\n",
    "pickle.dump(column_dict,handle2 , -1)\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> calculate the 2 low dimensionality projections of the distance between species -> 3d and 1d</h1>\n",
    "\n",
    "We can represent taxa that are closely grouped as colors that are similar to make reading figures easier. We can also group columns/labels based on taxonomic distance. These groupings won't take the hierarchy of the taxonomic tree into account though... all levels will be mixed together without much order ie([genus species family genus species] instead of [family genus genus genus species species species] )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle1 = open( './distmat.pkl','r')\n",
    "handle2 = open( './column_dict.pkl' , 'r')\n",
    "distmat = pickle.load(handle1)\n",
    "column_dict = pickle.load(handle2)\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "\n",
    "from sklearn.manifold import MDS \n",
    "\n",
    "#embed the species to 3d space\n",
    "mdsobj = MDS(n_components=3, metric=True, n_init=4, max_iter=300, verbose=0, eps=0.001, n_jobs=-2, random_state=None, dissimilarity= \"precomputed\")\n",
    "embeddings3d = mdsobj.fit_transform(distmat)\n",
    "\n",
    "#embed the species to 1d space\n",
    "mdsobj = MDS(n_components=1, metric=True, n_init=4, max_iter=300, verbose=0, eps=0.001, n_jobs=-2, random_state=None, dissimilarity=\"precomputed\")\n",
    "embeddings1d = mdsobj.fit_transform(distmat)\n",
    "\n",
    "#save the matrices\n",
    "handle1 = open( './embeddings3d.pkl' , 'w')\n",
    "handle2 = open( './embeddings1d.pkl', 'w')\n",
    "pickle.dump( embeddings3d,handle1 , -1 )\n",
    "pickle.dump( embeddings1d,handle2 , -1 )\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>plot the low dimensional mapping of the species tree onto the color and column space<h1>\n",
    "to play around with the Hog presence matrix it will be useful to define a color scheme for all of the species so that we can see if we're using taxonomically diverse or taxonomically homogenous datasets at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5fb0e3925386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcolumn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0membeddings3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0membeddings1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mhandle1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from colour import Color\n",
    "#create color and column mapping\n",
    "def coord_to_color(coord):\n",
    "    x,y,z= coord[0:3]\n",
    "    c = Color(rgb=(x,y,z))\n",
    "    return c.hex\n",
    "\n",
    "import pickle\n",
    "handle1 = open( './distmat.pkl','r')\n",
    "handle2 = open( './column_dict.pkl' , 'r')\n",
    "handle3= open('./embeddings3d.pkl' , 'r')\n",
    "handle4= open('./embeddings1d.pkl', 'r')\n",
    "\n",
    "\n",
    "distmat = pickle.load(handle1)\n",
    "column_dict = pickle.load(handle2)\n",
    "embeddings3d = pickle.load(handle3)\n",
    "embeddings1d = pickle.load(handle4)\n",
    "\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "handle3.close()\n",
    "handle4.close()\n",
    "\"\"\"\n",
    "handle1= open('./IDtoName.pkl','r')\n",
    "handle2= open('./NameToID.pkl','r')\n",
    "NametoID = pickle.load(handle2)\n",
    "IdtoName= pickle.load(handle1)\n",
    "handle1.close()\n",
    "handle2.close()\"\"\"\n",
    "\n",
    "#columndict is code to column\n",
    "#build column to code dictonary\n",
    "column_dictReverse = dict(zip( column_dict.values() , column_dict.keys()))\n",
    "\n",
    "#transform the 3d embedding into a color scheme\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "embeddings3dScaled = scaler.fit_transform(embeddings3d)\n",
    "colors = np.apply_along_axis( coord_to_color ,  1 , embeddings3dScaled)\n",
    "\n",
    "#dictionary from TaxId to color\n",
    "colorTaxaDict = dict(zip(column_dict.keys(),list(colors) ) ) \n",
    "TaxacolorDict = dict(zip( list(colors) , column_dict.keys() ))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#plot species tree in 3d space w colors\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d' )\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "ax.scatter( embeddings3dScaled[:,0], embeddings3dScaled[:,1], embeddings3dScaled[:,2], color = colors  )\n",
    "\n",
    "random_species = np.random.randint(0, len(column_dict)-1, 20)\n",
    "\n",
    "#label a small random subset of taxa as a sanity check\n",
    "def getspecies(input):\n",
    "    return IdtoName[column_dictReverse[input]]\n",
    "\n",
    "labels = np.vectorize(getspecies)(random_species)\n",
    "coords = embeddings3dScaled[random_species , :]\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax.text( coords[i,0] , coords[i,1] , coords[i,2], label , size = 10 , color = 'k' )\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings1d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-12f1a14a2a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#reorder matrix columns based on 1d Mapping and save everything to use on the HOG data matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdistmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings1d' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#reorder matrix columns based on 1d Mapping and save everything to use on the HOG data matrix\n",
    "\n",
    "columns = np.argsort(embeddings1d, axis = 0)\n",
    "columns = columns.flatten()\n",
    "distmat = distmat[columns,:]\n",
    "distmat = distmat[:, columns]\n",
    "embeddings3d = embeddings3d[columns,:]\n",
    "\n",
    "colors = colors[columns]\n",
    "\n",
    "#maps taxID to a matrix column\n",
    "column_dict=dict(zip( column_dict.keys(), list(columns)  ) )\n",
    "column_dictReverse=dict(zip( list(columns) , column_dictReverse.values() ) )\n",
    "\n",
    "handle1 = open( 'column_dictFinal.pkl')\n",
    "handle2 = open( 'column_dictReversFinal.pkl')\n",
    "handle3 = open( 'colorsFinal.pkl')\n",
    "pickle.dump(column_dict, handle1 , -1)\n",
    "pickle.dump(column_dictReverse, handle2 , -1)\n",
    "pickle.dump(colors, handle3 , -1)\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "handle3.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
