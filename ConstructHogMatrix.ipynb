{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "import pandas as pd\n",
    "omadatalocation = '/data/databases/OMA/OMA.2.1.1/data/OmaServer.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "omadata = tb.open_file(omadatalocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description([('Fam', '()i4'), ('ID', '()S255'), ('Level', '()S255')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tables/leaf.py:396: PerformanceWarning: The Leaf ``/_i_HogLevel/ID/sorted`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(omadata.root.HogLevel.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(299330, 'HOG:0299330', 'Chromadorea')\n",
      " (299330, 'HOG:0299330', 'Pristionchus pacificus')\n",
      " (299330, 'HOG:0299330', 'Onchocercidae')\n",
      " (299330, 'HOG:0299330', 'Brugia malayi')\n",
      " (299330, 'HOG:0299330', 'Loa loa')\n",
      " (299330, 'HOG:0299330', 'Onchocerca volvulus')\n",
      " (299330, 'HOG:0299330', 'Rhabditida')\n",
      " (299330, 'HOG:0299330', 'Strongyloides ratti')\n",
      " (299330, 'HOG:0299330', 'Caenorhabditis')\n",
      " (299330, 'HOG:0299330', 'Caenorhabditis brenneri')]\n"
     ]
    }
   ],
   "source": [
    "print(omadata.root.HogLevel[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using sets to count the unique occurences in each column</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "taxa\n",
      "2715332\n",
      "Hogs\n",
      "589223\n",
      "Fams\n",
      "17467463\n",
      "entries\n"
     ]
    }
   ],
   "source": [
    "Taxa = set([])\n",
    "Hogs = set([])\n",
    "Fams = set([])\n",
    "rows = 0\n",
    "\n",
    "for row in omadata.root.HogLevel:\n",
    "    Taxa.add(row[2])\n",
    "    Hogs.add(row[1])\n",
    "    Fams.add(row[0])\n",
    "    rows+=1\n",
    "\n",
    "print(len(Taxa))\n",
    "print('taxa')\n",
    "print(len(Hogs))\n",
    "print('Hogs')\n",
    "print(len(Fams))\n",
    "print('Fams')\n",
    "print(rows)\n",
    "print('entries')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "handle1 = open('./hogs.pkl','w')\n",
    "handle2= open('./fams.pkl','w')\n",
    "handle3 = open('./taxa.pkl','w')\n",
    "\n",
    "pickle.dump(Hogs,handle1,-1)\n",
    "pickle.dump(Fams,handle2,-1)\n",
    "pickle.dump(Taxa,handle3,-1)\n",
    "\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "handle3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create a dictionary for HOGs and families </h1> The taxonomy dict isn't really necesary since we have one from the other taxonomy notebook that will be more useful in selecting our reference taxa later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the column dictionary from the taxonomic analysis here\n",
    "import pickle\n",
    "import numpy as np\n",
    "handle1 = open('./column_dict.pkl', 'r')\n",
    "handle2= open('./NameToID.pkl','r')\n",
    "\n",
    "NameToID = pickle.load(handle2, )\n",
    "column_dict = pickle.load(handle1)\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "\n",
    "\n",
    "handle1 = open('./hogs.pkl','r')\n",
    "handle2= open('./fams.pkl','r')\n",
    "handle3 = open('./taxa.pkl','r')\n",
    "\n",
    "Hogs = pickle.load(handle1)\n",
    "Fams = pickle.load(handle2)\n",
    "Taxa = pickle.load(handle3)\n",
    "\n",
    "handle1.close()\n",
    "handle2.close()\n",
    "handle3.close()\n",
    "\n",
    "\n",
    "coldict={}\n",
    "coldictReverse = {}\n",
    "for i,taxon in enumerate(Taxa):\n",
    "    coldict[taxon]=i\n",
    "    coldictReverse[i] = taxon\n",
    "rowdict={}\n",
    "rowdictReverse={}\n",
    "#define a row for each unique hog\n",
    "for i,hog in enumerate(Hogs):\n",
    "    rowdict[hog]= i\n",
    "    rowdictReverse[i]=hog\n",
    "rowdictFam ={}\n",
    "rowdictFamReverse = {}\n",
    "#define a row for each unique family\n",
    "#dont know if we'll use this...\n",
    "for i,fam in enumerate(Fams):\n",
    "    rowdictFam[fam] = i\n",
    "    rowdictFamReverse[i]=fam\n",
    "\n",
    "\n",
    "\n",
    "colmax=max(column_dict.values())+1\n",
    "rowmax=len(Hogs)+1\n",
    "\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def retMatrixChunk( Hogdatachunk ):\n",
    "    matrix = lil_matrix((rowmax,colmax))\n",
    "    fams,hogs,taxa =Hogdatachunk\n",
    "    matrix[ ([rowdict[hog] for hog in hogs] , [column_dict[NameToID [taxon]] for taxon in taxa] ) ] = 1\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def retMatrixindex( Hogdatachunk ):\n",
    "    fams,hogs,taxa =Hogdatachunk\n",
    "    return ([rowdict[hog] for hog in hogs] , [column_dict[NameToID [taxon]] for taxon in taxa] ) \n",
    "\n",
    "def returnDataChunk( HogData , chunksize):\n",
    "    i=0\n",
    "    chunk =[]\n",
    "    while len(chunk) > 0 or i == 0:\n",
    "        chunk = HogData[i*chunksize:(i+1)*chunksize]\n",
    "        fams,hogs,taxa = zip(*chunk)\n",
    "        i +=1\n",
    "        yield [fams, hogs, taxa]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just testing out the generator and the transformation to sparse matrix format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00739299999999\n",
      "0.000868000000011\n",
      "0.000579000000002\n",
      "0.000332\n",
      "0.000570999999994\n",
      "0.000325000000004\n",
      "0.000602999999998\n",
      "0.000478999999999\n",
      "0.000529999999998\n",
      "0.000480999999994\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "it = returnDataChunk(omadata.root.HogLevel,100)\n",
    "for x in range(10):\n",
    "    start = time.clock()\n",
    "\n",
    "    retMatrixindex(next(it))\n",
    "\n",
    "    print(str( time.clock()-start ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transform taxonomic levels in OMA to sparse matrix</h1>\n",
    "To avoid passing vars around we'll use queues to pass chunks of OMA and return chunks of the final matrix.\n",
    "\n",
    "Each taxonomic level corresponds to a column and each row corresponds to a HOG. This takes an hour or two to calculate for all Hogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#return datachunks to MP function\n",
    "chunksize = 10000\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import time\n",
    "import gc\n",
    "import sys \n",
    "import redis\n",
    "\n",
    "\n",
    "datagenerator = returnDataChunk(omadata.root.HogLevel, chunksize ) \n",
    "\n",
    "def worker(q,retq,l):\n",
    "    while True:\n",
    "        data = q.get()\n",
    "        if data == 'DONE':\n",
    "            break\n",
    "        indices = retMatrixindex(data)\n",
    "        retq.put(indices)\n",
    "        del data\n",
    "        gc.collect()  \n",
    "def updater(q,retq,l):\n",
    "    cooevolution_matrix = lil_matrix( (rowmax,colmax) )\n",
    "    while True:\n",
    "        indices = retq.get()\n",
    "        if indices == 'DONE':\n",
    "            break\n",
    "        cooevolution_matrix[indices] = 1\n",
    "        del indices\n",
    "        gc.collect()\n",
    "    q.put(cooevolution_matrix)\n",
    "\n",
    "l = mp.Lock()\n",
    "cores = mp.cpu_count()\n",
    "q = mp.Queue(maxsize = int(cores/1.5))\n",
    "retq = mp.Queue(maxsize = int(cores/1.5))\n",
    "\n",
    "processes =[]\n",
    "\n",
    "for i in range(cores):\n",
    "    t = mp.Process(target=worker, args=(q,retq,l)  ) \n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "    processes.append(t)\n",
    "\n",
    "u = mp.Process(target=updater, args=(q,retq,l)  ) \n",
    "u.daemon = True\n",
    "u.start()\n",
    "\n",
    "count =0\n",
    "start = 0\n",
    "stop = chunksize\n",
    "data = zip(*omadata.root.HogLevel[start:stop])\n",
    "q.put(data)\n",
    "\n",
    "start = time.clock\n",
    "while len(data)>0:\n",
    "    time.sleep(1)\n",
    "    while q.full() == False:\n",
    "        count += 1\n",
    "        start = stop\n",
    "        stop+=chunksize\n",
    "        data = zip(*omadata.root.HogLevel[start:stop])\n",
    "        if len(data) == 0:\n",
    "            for p in range(len(processes)):\n",
    "                q.put('DONE')\n",
    "            break\n",
    "        else:\n",
    "            q.put(data)\n",
    "\n",
    "            \n",
    "retq.put('DONE')\n",
    "cooevolution_matrix = q.get()        \n",
    "print 'DONE!!!!!'\n",
    "#save the matrix\n",
    "stop = time.clock()\n",
    "print 'hours'\n",
    "print (stop - start) / 3600\n",
    "handle1=open('./BigCoEvMatrix.pkl' , 'w')\n",
    "pickle.dump(cooevolution_matrix,handle1, -1)\n",
    "handle1.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy.sparse import find\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "handle1 =open('./BigCoEvMatrix.pkl' , 'r')\n",
    "cooevolution_matrix = pickle.load(handle1)\n",
    "handle1.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, LeanMinHash , MinHashLSHForest, HyperLogLogPlusPlus\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def returnHashes(data, verbose= False):\n",
    "    rowstart, rowend , dataChunk = data\n",
    "    indices = np.vstack( find( dataChunk )).astype(np.int).T\n",
    "    if verbose == True:\n",
    "        print indices \n",
    "    hashes ={}\n",
    "    #update hashes with presence in species\n",
    "    for row in range(indices.shape[0]):\n",
    "        hashes[rowstart+indices[row,0]] = MinHash()\n",
    "        hashes[rowstart+indices[row,0]].update( indices[row,1] )\n",
    "    #turn to small hashes\n",
    "    for row in hashes.keys():\n",
    "        hashes[row]=LeanMinHash(hashes[row])\n",
    "    del dataChunk\n",
    "    gc.collect()\n",
    "    return hashes\n",
    "\n",
    "def chopMatrix(bigMatrix,chunksize):\n",
    "    i =0\n",
    "    leftovers = bigMatrix.shape[0]%chunksize\n",
    "    \n",
    "    while i <  bigMatrix.shape[0] - leftovers :\n",
    "        chunk = bigMatrix[i:i+chunksize,:]\n",
    "        yield [i,i+chunksize,chunk]\n",
    "        i+=chunksize\n",
    "    yield [i,i+leftovers,bigMatrix[i:i+leftovers,:]]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> test out the generator and Hashing functions </h1>\n",
    "The generator chops a matrix into blocks of Nrows. The hashing function assigns hash to each HOG rownumber and updates it based on which columns are positive. When the updates are finished the hash is turned to a LeanMinHash with a smaller memory footprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 874    0    1]\n",
      " [ 997    0    1]\n",
      " [1546    0    1]\n",
      " ..., \n",
      " [9506 4166    1]\n",
      " [9508 4166    1]\n",
      " [9509 4166    1]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d2b4d97ec3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchopMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooevolution_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturnHashes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-aaa9d3db57b8>\u001b[0m in \u001b[0;36mreturnHashes\u001b[0;34m(data, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mhashes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLeanMinHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdataChunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "data = next(chopMatrix(cooevolution_matrix,10000))\n",
    "start = time.clock()\n",
    "print len(returnHashes(data, verbose= True))\n",
    "print time.clock()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>  calculate a hash for each HOG</h1> the same multiprocessing strategy as before expcept an updater process has the LSFforest and adds the hashes as they are calculated instead of using the main loop in the notebook. The end result is a dictionary of Hashes for each Hog and an LSF forest that includes all the Hashes and is searchable with a hash.\n",
    "\n",
    "\n",
    "The top N neighbors for each HOG can be used as a threshold to avoid calculating other more costly distance metrics for all the HOGs vs all the HOGs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61865 stored elements in LInked List format>]\n",
      "[10000, 20000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62495 stored elements in LInked List format>]\n",
      "[20000, 30000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66082 stored elements in LInked List format>]\n",
      "[30000, 40000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62334 stored elements in LInked List format>]\n",
      "[40000, 50000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62752 stored elements in LInked List format>]\n",
      "[50000, 60000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67482 stored elements in LInked List format>]\n",
      "[60000, 70000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68744 stored elements in LInked List format>]\n",
      "[70000, 80000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59787 stored elements in LInked List format>]\n",
      "[80000, 90000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61923 stored elements in LInked List format>]\n",
      "done hashing\n",
      "done hashing\n",
      "done hashing\n",
      "[90000, 100000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66038 stored elements in LInked List format>]\n",
      "[100000, 110000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61580 stored elements in LInked List format>]\n",
      "[110000, 120000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61571 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "update done\n",
      "update done\n",
      "[120000, 130000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63983 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[130000, 140000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66070 stored elements in LInked List format>]\n",
      "[140000, 150000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63443 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[150000, 160000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59855 stored elements in LInked List format>]\n",
      "[160000, 170000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60422 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[170000, 180000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62475 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[180000, 190000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67495 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[190000, 200000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65831 stored elements in LInked List format>]\n",
      "update done\n",
      "[200000, 210000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67404 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[210000, 220000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63255 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "done hashing\n",
      "[220000, 230000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61888 stored elements in LInked List format>]\n",
      "[230000, 240000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60000 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "[240000, 250000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64341 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[250000, 260000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64067 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[260000, 270000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 70142 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[270000, 280000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62760 stored elements in LInked List format>]\n",
      "[280000, 290000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 70067 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[290000, 300000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63131 stored elements in LInked List format>]\n",
      "[300000, 310000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61316 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "update done\n",
      "[310000, 320000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 76350 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[320000, 330000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68223 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[330000, 340000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 57615 stored elements in LInked List format>]\n",
      "[340000, 350000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60183 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "update done\n",
      "[350000, 360000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62577 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[360000, 370000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65853 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[370000, 380000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61326 stored elements in LInked List format>]\n",
      "[380000, 390000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63407 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[390000, 400000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63120 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[400000, 410000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62106 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[410000, 420000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65030 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[420000, 430000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60315 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[430000, 440000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68768 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[440000, 450000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62905 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[450000, 460000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 69580 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "[460000, 470000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60844 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[470000, 480000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61844 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[480000, 490000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64057 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[490000, 500000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64834 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "done hashing\n",
      "[500000, 510000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60056 stored elements in LInked List format>]\n",
      "[510000, 520000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59962 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[520000, 530000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64646 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[530000, 540000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65560 stored elements in LInked List format>]\n",
      "[540000, 550000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61929 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[550000, 560000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63565 stored elements in LInked List format>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update done\n",
      "done hashing\n",
      "[560000, 570000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63382 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[570000, 580000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62658 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[580000, 590000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65787 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "update done\n",
      "[590000, 600000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 69767 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[600000, 610000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62773 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[610000, 620000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65800 stored elements in LInked List format>]\n",
      "done hashing\n",
      "done hashing\n",
      "[620000, 630000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62162 stored elements in LInked List format>]\n",
      "update done\n",
      "[630000, 640000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62373 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[640000, 650000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62790 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[650000, 660000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63647 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[660000, 670000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62575 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[670000, 680000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63073 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[680000, 690000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68849 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[690000, 700000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62102 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[700000, 710000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63191 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[710000, 720000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62446 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[720000, 730000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 58798 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[730000, 740000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63672 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[740000, 750000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59777 stored elements in LInked List format>]\n",
      "[750000, 760000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66971 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[760000, 770000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67425 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[770000, 780000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 58228 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[780000, 790000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65743 stored elements in LInked List format>]\n",
      "[790000, 800000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62720 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[800000, 810000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64384 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[810000, 820000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61411 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "[820000, 830000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63642 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "[830000, 840000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64641 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[840000, 850000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67651 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[850000, 860000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65415 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[860000, 870000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61130 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[870000, 880000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63064 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[880000, 890000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 70310 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[890000, 900000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67312 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[900000, 910000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64300 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[910000, 920000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64610 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[920000, 930000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63736 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[930000, 940000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60987 stored elements in LInked List format>]\n",
      "[940000, 950000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60169 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "update done\n",
      "[950000, 960000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62653 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[960000, 970000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61505 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[970000, 980000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61428 stored elements in LInked List format>]\n",
      "[980000, 990000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61317 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[990000, 1000000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61989 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1000000, 1010000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60041 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "done hashing\n",
      "[1010000, 1020000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 67307 stored elements in LInked List format>]\n",
      "[1020000, 1030000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63984 stored elements in LInked List format>]\n",
      "[1030000, 1040000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61439 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1040000, 1050000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61276 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[1050000, 1060000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66577 stored elements in LInked List format>]\n",
      "[1060000, 1070000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68681 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1070000, 1080000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63653 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1080000, 1090000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59596 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1090000, 1100000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62622 stored elements in LInked List format>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update done\n",
      "done hashing\n",
      "[1100000, 1110000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59284 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1110000, 1120000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65820 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1120000, 1130000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61006 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1130000, 1140000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63881 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1140000, 1150000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65045 stored elements in LInked List format>]\n",
      "done hashing\n",
      "update done\n",
      "[1150000, 1160000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63420 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1160000, 1170000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66005 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1170000, 1180000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 72629 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[1180000, 1190000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61718 stored elements in LInked List format>]\n",
      "[1190000, 1200000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65508 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1200000, 1210000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64495 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1210000, 1220000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 71751 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1220000, 1230000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62910 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1230000, 1240000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61766 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1240000, 1250000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 58905 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1250000, 1260000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66562 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1260000, 1270000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63250 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1270000, 1280000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63296 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1280000, 1290000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61016 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1290000, 1300000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63613 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[1300000, 1310000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61310 stored elements in LInked List format>]\n",
      "[1310000, 1320000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61238 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1320000, 1330000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66087 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1330000, 1340000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 68453 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1340000, 1350000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62748 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1350000, 1360000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66023 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1360000, 1370000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64797 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1370000, 1380000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 59000 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[1380000, 1390000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62878 stored elements in LInked List format>]\n",
      "[1390000, 1400000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 58976 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1400000, 1410000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62976 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1410000, 1420000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63561 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1420000, 1430000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64115 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1430000, 1440000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63877 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1440000, 1450000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64292 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1450000, 1460000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62071 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1460000, 1470000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 60473 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1470000, 1480000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 66469 stored elements in LInked List format>]\n",
      "done hashing\n",
      "[1480000, 1490000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65772 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1490000, 1500000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63272 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1500000, 1510000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62386 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "done hashing\n",
      "[1510000, 1520000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65568 stored elements in LInked List format>]\n",
      "[1520000, 1530000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65989 stored elements in LInked List format>]\n",
      "update done\n",
      "update done\n",
      "done hashing\n",
      "[1530000, 1540000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63954 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1540000, 1550000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64179 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1550000, 1560000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 61771 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1560000, 1570000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62812 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1570000, 1580000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64054 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1580000, 1590000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 65964 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1590000, 1600000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 62552 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1600000, 1610000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64914 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1610000, 1620000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64759 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1620000, 1630000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 69015 stored elements in LInked List format>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update done\n",
      "done hashing\n",
      "[1630000, 1640000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 64803 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1640000, 1650000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 70815 stored elements in LInked List format>]\n",
      "update done\n",
      "done hashing\n",
      "[1650000, 1660000, <10000x4167 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 63661 stored elements in LInked List format>]\n",
      "update done\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, LeanMinHash , MinHashLSHForest, HyperLogLogPlusPlus\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import redis\n",
    "\n",
    "#use min hashing to generate a hash for each HOG and an LSH forest with all hashes\n",
    "#use the jackard distance with LSH forest to grab top N hits for each HOG-> use as threshhold for distance matrices\n",
    "\n",
    "def worker(q,retque,l):\n",
    "    while True:\n",
    "        time.sleep(.01)\n",
    "        data = q.get()\n",
    "        if data == 'DONE':\n",
    "            break\n",
    "        obj = returnHashes(data)\n",
    "        print 'done hashing'\n",
    "        retq.put(obj)\n",
    "        del obj\n",
    "        del data\n",
    "        gc.collect()\n",
    "       \n",
    "def updater(r,q,retq,l):\n",
    "    forest = MinHashLSHForest(num_perm=128, l=8)\n",
    "    hashesPath = './HOGhashdict'\n",
    "    i=0\n",
    "    \n",
    "    while True:\n",
    "        data = retq.get()\n",
    "        if data == 'DONE':\n",
    "            break\n",
    "        for key in data:\n",
    "            r.set(key, pickle.dumps(data[key]))\n",
    "        #bigdict.update(data)\n",
    "        #if len(bigdict)> 100000:\n",
    "        #    with open(hashesPath + str(i)+'.pkl' , 'w') as pickledump:\n",
    "        #        pickle.dump(bigdict,pickledump,-1)\n",
    "        #    bigdict = {}\n",
    "        \n",
    "        i +=1\n",
    "        print 'update done'\n",
    "        del data\n",
    "        gc.collect()\n",
    "    #pass the final result back\n",
    "    q.put((r,forest) )\n",
    "\n",
    "\n",
    "chunksize = 10000\n",
    "l = mp.Lock()\n",
    "cores = mp.cpu_count()\n",
    "q = mp.Queue(maxsize = cores/4)\n",
    "retq = mp.Queue(maxsize = cores/4)\n",
    "hpp = HyperLogLogPlusPlus()\n",
    "iterator = chopMatrix(cooevolution_matrix,chunksize)\n",
    "r = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "\n",
    "processes =[]\n",
    "for i in range(cores/4):\n",
    "    t = mp.Process(target=worker, args=(q,retq,l)  ) \n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "    u = mp.Process(target=updater, args=(r,q,retq,l)  ) \n",
    "    u.daemon = True\n",
    "    u.start()\n",
    "    processes.append(t)\n",
    "    processes.append(u)\n",
    "    count =0\n",
    "while q.empty()==False or count == 0:\n",
    "    time.sleep(.1)\n",
    "    while True:\n",
    "        count += 1\n",
    "        try:\n",
    "            data = next(iterator)\n",
    "            print data\n",
    "            q.put(data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "for p in processes:\n",
    "    q.put('DONE')\n",
    "retq.put('DONE')\n",
    "\n",
    "forest = q.get()\n",
    "#construct the fores here ? \n",
    "q.close()\n",
    "retq.close()\n",
    "del iterator\n",
    "del q\n",
    "del retq\n",
    "gc.collect()\n",
    "\n",
    "#save forest and dictionary.\n",
    "forest.index()\n",
    "handle1 = open('bigforest', 'w' )\n",
    "pickle.dump(forest , handle1, -1)\n",
    "handle1.close()\n",
    "\n",
    "print 'DONE!!!!!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the hamming distance matrix between all hogs using the full matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#calculate the prob of 0 or the prob of 1 for each row\n",
    "def prob_x_y_forBinary_M(two_rows):\n",
    "    px_one = np.sum(two_rows[0,:])/two_rows.shape[1]\n",
    "    px_zero = 1-px_one\n",
    "    py_one = np.sum(two_rows[1,:])/two_rows.shape[1]\n",
    "    py_zero = 1-py_one\n",
    "    return np.array( [px_zero, px_one]), np.array([py_zero, py_one])\n",
    "\n",
    "\n",
    "\n",
    "def pxy_coocurrence_between_two_M(m):\n",
    "    #4 cases for two binary vectors. (x=1,y=1), (x=0,y=1), (x=1,y=0), (x=0,y=0) \n",
    "    #use matrix multiplication to get cooccurences between rows for all cases\n",
    "    pxy_case1 = tf.multiply(m,m.T)/m.shape[1]\n",
    "    pxy_case2 = tf.multiply(1-m, m.T )/m.shape[1]\n",
    "    pxy_case3 = tf.multiply(m, 1-m.T)/m.shape[1]\n",
    "    pxy_case4 =1 -tf.add([pxy_case1, pxy_case2 , pxy_case3])\n",
    "    #Ncase 4 is whatever is leftover\n",
    "    return pxy_case1, pxy_case2,pxy_case3, pxy_case4\n",
    "\n",
    "def MI(probx,proby, cooccurenceMat ):\n",
    "    #calculate MI of two rows\n",
    "    px,py = prob_x_y(two_rows)\n",
    "    pxy = pxy_coocurrence_between_two_rows(two_rows)\n",
    "    MI=0\n",
    "    for x in [0,1]:\n",
    "        for y in [0,1]:\n",
    "                MI+= pxy[x,y]*np.log( pxy[x,y] / (px[x] * py[y]) ) \n",
    "    return MI\n",
    "\n",
    "def Hamming_dist(cooccurenceMats):\n",
    "    return coocurrenceMats[1]*coocurrenceMats[1].shape[1]+cooccurenceMats[2]*coocurrenceMats[1].shape[1]\n",
    "\n",
    "def jaccard_dist(two_rows):\n",
    "    pxy = pxy_coocurrence_between_two_rows(two_rows)\n",
    "    return (pxy[0,0]+pxy[1,1] - pxy[0,1]+pxy[1,0]) / pxy[0,0]+pxy[1,1] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge hogs -> merge hashes\n",
    "\n",
    "def mergeHogs()\n",
    "    \n",
    "results = pool.map( )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run PCA to filter out overrepresented species and project reduced matrix down to species subspace\n",
    "\n",
    "\n",
    "\n",
    "#calculate distance metrics in species subpspace\n",
    "\n",
    "    #hamming\n",
    "    #euclidian\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
